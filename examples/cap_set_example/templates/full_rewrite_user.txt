## TASK SPECIFICATION (FINAL, FULL VERSION)

You are to produce or improve a **complete, runnable Python module** that constructs a large cap set in ( \mathbb{F}_3^n ) using **exactly one fixed algorithmic structure**.

---

### IMPORTANT

* The evaluator will call `generate_set(8)` **exactly once**.
* **Internal parameter tuning via Optuna is mandatory**.
* The **algorithmic structure must remain invariant** across all Optuna trials and runs.

---

## ─────────────────────────────────────────────

## PROBLEM

## ─────────────────────────────────────────────

A **cap set** is a subset ( A \subset \mathbb{F}_3^n ) such that there do **not** exist three **distinct** elements
( x, y, z \in A ) satisfying:

[
x + y + z \equiv 0 \pmod 3
]

coordinate-wise.

Your goal is to **maximize ( |A| )**.
**Correctness is mandatory.**

---

## ─────────────────────────────────────────────

## CRITICAL DESIGN CONSTRAINTS (DO NOT VIOLATE)

## ─────────────────────────────────────────────

### 1. EXACTLY ONE ALGORITHMIC STRATEGY

* Do **NOT** switch between different construction paradigms.
* Do **NOT** introduce strategy-selection flags, modes, or categorical choices.
* Control flow, data structures, and representations **must be identical** in all runs and trials.

---

### 2. STABLE SEMANTICS FOR ALL PARAMETERS

Tunable parameters may affect **only**:

* Priority / scoring weights
* Smooth stochastic noise or tie-breaking perturbations
* Thresholds or numeric limits
* Iteration or pass counts

Parameters **MUST NOT**:

* Enable or disable major code paths
* Select between different algorithms
* Change data representations or construction logic

---

### 3. PARAMETER TUNING REQUIREMENTS

* All Optuna trials **must optimize the same objective function** ( f(\text{params}) ).
* Prefer a **small number of parameters** (approximately 4–7) with smooth, continuous influence.
* The objective function **may average results over multiple fixed random seeds** to reduce noise.

---

## STRUCTURE GUIDANCE (STRONG, SEMI-MANDATORY)

The construction **MUST** strictly preserve the following **core algorithmic framework**, which is **invariant across all runs and all Optuna trials**:

* **Start from the empty set** in ( \mathbb{F}_3^n ).
* **Iteratively grow the cap set by greedy selection**, adding points one at a time.
* At each iteration:

  * The algorithm maintains a **current partial cap set**, consisting of all points selected so far.
  * **All remaining candidate points are assigned a priority score**, where the priority function **explicitly depends on the current cap set**.
  * **Priority scores MUST be recomputed from scratch at every iteration**, fully reflecting the updated state after the most recently added point.
* The algorithm **selects the candidate point with the highest priority score** that does not violate the cap set constraint.
* The selected point is **permanently added** to the cap set.
* The construction **terminates when no further candidate point can be added** without violating the cap set property.

This **state-dependent, dynamically re-evaluated greedy construction** is the **only permitted global control structure**.

---

### Core Invariant

At every iteration, the following invariant **MUST hold**:

> **“All candidate points are totally ordered by a priority function that is recomputed based solely on the current cap set and fixed tunable parameters.”**

The algorithm **MUST NOT** reuse, cache, incrementally update, or partially preserve priority scores across iterations, unless such behavior is **semantically equivalent to a full recomputation** under the same priority definition.

---

### Allowed Degrees of Freedom

*(ALL MUST RESPECT THE ABOVE FRAMEWORK)*

Performance improvements are permitted **only through the design of the priority function**, including:

* The **features** used to score candidate points
  (e.g. coordinate statistics, symmetry indicators, or interactions with the current cap set).
* The **weights or coefficients** applied to these features.
* Smooth stochastic perturbations or deterministic noise used solely for tie-breaking.
* Soft normalization, rescaling, or reweighting of priority scores.
* Limited implicit lookahead **expressed exclusively through priority computation**,
  not via branching, backtracking, or alternative control flow.

All such modifications **MUST preserve** the invariant that:

> **“Each iteration considers candidate points in a single global order fully determined by freshly computed priority scores.”**

---

### Explicitly Forbidden Modifications

The following are **strictly prohibited**:

* Fixing, precomputing, or caching a global priority order that is reused across iterations.
* Incrementally updating priorities in a manner that depends on historical ordering rather than full recomputation.
* Introducing multiple construction phases, passes, or modes.
* Performing swaps, removals, rollbacks, or backtracking of previously added points.
* Running multiple independent constructions and selecting the best result.
* Switching between different construction strategies or paradigms.
* Any control flow that conditionally alters the algorithmic structure.

---

### Design Philosophy

The intended design philosophy is:

> **One fixed greedy algorithm, whose expressive power comes entirely from a state-dependent priority function that is recomputed after every selection.**

All learning, tuning, and experimentation should therefore focus on:

* Designing priority features that meaningfully capture interactions with the current cap set.
* Calibrating their parameters via smooth, continuous optimization.
* Understanding how dynamic priority recomputation shapes the growth trajectory of the cap set.

## ─────────────────────────────────────────────

## PARAMETER TUNING REQUIREMENT (MANDATORY)

## ─────────────────────────────────────────────

The algorithm **MUST use Optuna for automatic parameter tuning**, and it **may assume that Optuna is always available** in the execution environment.

No fallback implementation for the absence of Optuna is required.

Mandatory requirements:

* All tunable parameters **MUST be provided by Optuna trials**.
* All trials **MUST execute the identical algorithmic structure** described above.
* All trials **MUST optimize the same objective function**, whose primary goal is maximizing the final cap set size.
* Optuna **MUST use the TPE sampler** (`optuna.samplers.TPESampler`).
* Optuna **MUST NOT** be used for:

  * Algorithm or strategy selection
  * Enabling or disabling functionality
  * Switching construction paradigms

Within `generate_set`:

* A **bounded Optuna study** (by trial count or time limit) **MUST be executed first**.
* The **best trial’s parameters** MUST then be used to run **one final deterministic construction**.
* The cap set produced by this final run **MUST be returned**.

---

## ─────────────────────────────────────────────

## API REQUIREMENTS

## ─────────────────────────────────────────────

The module **MUST** define:

```python
def generate_set(n: int) -> List[Tuple[int, ...]]
```

* The evaluator will call `generate_set(8)`.
* The function must always return a **valid cap set**.
* Runtime must be **bounded and predictable**.

Encapsulate the construction in a class, e.g.:

```python
class CapSetBuilder:
    def __init__(self, params, seed):
        ...
    def build(self) -> List[int]:
        ...
```

---

## ─────────────────────────────────────────────

## DETERMINISM

## ─────────────────────────────────────────────

* Define a module-level constant `_RANDOM_SEED`.
* Seed all RNGs deterministically.
* Given identical parameters, output **must be reproducible**.

---

## ─────────────────────────────────────────────

## DOCUMENTATION (LIGHTWEIGHT)

## ─────────────────────────────────────────────

At the top of the file, briefly describe:

* The fixed algorithmic idea
* The meaning of each tunable parameter

Do **NOT** include external references or excessive explanation.

---

## ─────────────────────────────────────────────

## OUTPUT FORMAT

## ─────────────────────────────────────────────

Return **ONLY** a complete Python module enclosed in:

```python
<full module text>
```

---

## ─────────────────────────────────────────────

## CURRENT PROGRAM CONTEXT (FILLED BY SYSTEM)

## ─────────────────────────────────────────────

Parent program code (base to improve):
```python
{current_program}
```

Metrics / fitness:
- {metrics}
- fitness_score: {fitness_score}
- feature_coords: {feature_coords}

Recent evolution highlights:
{improvement_areas}

Top/diverse attempts from this island:
{evolution_history}

Inspirations (same island):
{inspirations}

Artifacts (if available):
{artifacts}
