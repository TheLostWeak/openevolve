## TASK SPECIFICATION (FINAL, FULL VERSION)

You are to produce or improve a **complete, runnable Python module** that constructs a large cap set in ( \mathbb{F}_3^n ) using **exactly one fixed algorithmic structure**.

---

### IMPORTANT

* The evaluator will call `generate_set(8)` **exactly once**.
* **Internal parameter tuning via Optuna is mandatory**.
* The **algorithmic structure must remain invariant** across all Optuna trials and runs.

---

## ─────────────────────────────────────────────

## PROBLEM

## ─────────────────────────────────────────────

A **cap set** is a subset ( A \subset \mathbb{F}_3^n ) such that there do **not** exist three **distinct** elements
( x, y, z \in A ) satisfying:

[
x + y + z \equiv 0 \pmod 3
]

coordinate-wise.

Your goal is to **maximize ( |A| )**.
**Correctness is mandatory.**

---

## ─────────────────────────────────────────────

## CRITICAL DESIGN CONSTRAINTS (DO NOT VIOLATE)

## ─────────────────────────────────────────────

### 1. EXACTLY ONE ALGORITHMIC STRATEGY

* Do **NOT** switch between different construction paradigms.
* Do **NOT** introduce strategy-selection flags, modes, or categorical choices.
* Control flow, data structures, and representations **must be identical** in all runs and trials.

---

### 2. STABLE SEMANTICS FOR ALL PARAMETERS

Tunable parameters may affect **only**:

* Priority / scoring weights
* Smooth stochastic noise or tie-breaking perturbations
* Thresholds or numeric limits
* Iteration or pass counts

Parameters **MUST NOT**:

* Enable or disable major code paths
* Select between different algorithms
* Change data representations or construction logic

---

### 3. PARAMETER TUNING REQUIREMENTS

* All Optuna trials **must optimize the same objective function** ( f(\text{params}) ).
* Prefer a **small number of parameters** (approximately 4–7) with smooth, continuous influence.
* The objective function **may average results over multiple fixed random seeds** to reduce noise.

---

## ─────────────────────────────────────────────

## STRUCTURE GUIDANCE (STRONG, SEMI-MANDATORY)

## ─────────────────────────────────────────────

The construction **MUST** strictly preserve the following **core algorithmic framework**:

* **Start from the empty set** in ( \mathbb{F}_3^n ).
* **Iteratively grow the cap set by greedy selection**, adding points one by one.
* At each step, **all candidate points are assigned a priority score**.
* The algorithm **always attempts to add points in descending priority order**, skipping those that violate the cap set constraint.
* The construction **terminates when no further point can be added**.

This greedy, priority-driven incremental construction is the **only permitted global control structure**.

---

### Allowed Degrees of Freedom

*(ALL MUST RESPECT THE ABOVE FRAMEWORK)*

Performance improvements are permitted **only through the design of the priority function**, including:

* The **features** used to score candidate points
  (e.g. coordinate statistics, symmetry indicators, interaction with the current set).
* The **weights or coefficients** applied to these features.
* Smooth stochastic perturbations or deterministic tie-breaking noise applied to priority scores.
* Soft normalization, rescaling, or reweighting of priorities.
* Limited implicit lookahead **expressed solely via priority adjustments**
  (not via branching, backtracking, or alternative control flow).

All such modifications **must preserve** the invariant:

> **“Points are considered in a single global order determined entirely by their priority score.”**

---

### Explicitly Forbidden Modifications

The following are **strictly prohibited**:

* Introducing any non-empty structured seed (e.g. product or algebraic constructions).
* Performing swaps, removals, rollbacks, or backtracking of previously added points.
* Running multiple independent constructions and selecting the best result.
* Switching between different construction strategies.
* Any control flow that conditionally changes the algorithmic paradigm.

---

### Design Philosophy

The intended design philosophy is:

> **One fixed greedy algorithm, whose power comes entirely from a well-designed priority function.**

All learning, tuning, and experimentation should focus on:

* Designing expressive yet stable priority features.
* Calibrating their parameters.
* Understanding how priority choices shape the final cap set.

---

## ─────────────────────────────────────────────

## PARAMETER TUNING REQUIREMENT (MANDATORY)

## ─────────────────────────────────────────────

The algorithm **MUST use Optuna for automatic parameter tuning**, and it **may assume that Optuna is always available** in the execution environment.

No fallback implementation for the absence of Optuna is required.

Mandatory requirements:

* All tunable parameters **MUST be provided by Optuna trials**.
* All trials **MUST execute the identical algorithmic structure** described above.
* All trials **MUST optimize the same objective function**, whose primary goal is maximizing the final cap set size.
* Optuna **MUST use the TPE sampler** (`optuna.samplers.TPESampler`).
* Optuna **MUST NOT** be used for:

  * Algorithm or strategy selection
  * Enabling or disabling functionality
  * Switching construction paradigms

Within `generate_set`:

* A **bounded Optuna study** (by trial count or time limit) **MUST be executed first**.
* The **best trial’s parameters** MUST then be used to run **one final deterministic construction**.
* The cap set produced by this final run **MUST be returned**.

---

## ─────────────────────────────────────────────

## API REQUIREMENTS

## ─────────────────────────────────────────────

The module **MUST** define:

```python
def generate_set(n: int) -> List[Tuple[int, ...]]
```

* The evaluator will call `generate_set(8)`.
* The function must always return a **valid cap set**.
* Runtime must be **bounded and predictable**.

Encapsulate the construction in a class, e.g.:

```python
class CapSetBuilder:
    def __init__(self, params, seed):
        ...
    def build(self) -> List[int]:
        ...
```

---

## ─────────────────────────────────────────────

## DETERMINISM

## ─────────────────────────────────────────────

* Define a module-level constant `_RANDOM_SEED`.
* Seed all RNGs deterministically.
* Given identical parameters, output **must be reproducible**.

---

## ─────────────────────────────────────────────

## DOCUMENTATION (LIGHTWEIGHT)

## ─────────────────────────────────────────────

At the top of the file, briefly describe:

* The fixed algorithmic idea
* The meaning of each tunable parameter

Do **NOT** include external references or excessive explanation.

---

## ─────────────────────────────────────────────

## OUTPUT FORMAT

## ─────────────────────────────────────────────

Return **ONLY** a complete Python module enclosed in:

```python
<full module text>
```

---

## ─────────────────────────────────────────────

## CURRENT PROGRAM CONTEXT (FILLED BY SYSTEM)

## ─────────────────────────────────────────────

Parent program code (base to improve):
```python
{current_program}
```

Metrics / fitness:
- {metrics}
- fitness_score: {fitness_score}
- feature_coords: {feature_coords}

Recent evolution highlights:
{improvement_areas}

Top/diverse attempts from this island:
{evolution_history}

Inspirations (same island):
{inspirations}

Artifacts (if available):
{artifacts}
